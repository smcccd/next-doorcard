#!/usr/bin/env npx tsx

/**
 * MIGRATION VALIDATION SCRIPT
 *
 * This script validates the production migration by:
 * 1. Testing database connections
 * 2. Analyzing source data constraints
 * 3. Identifying potential duplicate issues
 * 4. Creating a migration plan with safety checks
 */

import { PrismaClient } from "@prisma/client";
import { parse } from "fast-csv";
import * as fs from "fs";

interface ValidationResult {
  sourceData: {
    users: number;
    doorcards: number;
    appointments: number;
  };
  constraints: {
    duplicateUsers: string[];
    duplicateDoorcards: Array<{
      username: string;
      college: string;
      count: number;
    }>;
    orphanedAppointments: number;
  };
  recommendations: string[];
  canProceed: boolean;
}

async function validateMigration(): Promise<ValidationResult> {
  console.log("üîç MIGRATION VALIDATION STARTING...\n");

  const result: ValidationResult = {
    sourceData: { users: 0, doorcards: 0, appointments: 0 },
    constraints: {
      duplicateUsers: [],
      duplicateDoorcards: [],
      orphanedAppointments: 0,
    },
    recommendations: [],
    canProceed: false,
  };

  // 1. Test Database Connection
  console.log("üì° Testing Neon PostgreSQL connection...");
  const neonUrl = process.env.DATABASE_URL;
  if (
    !neonUrl ||
    (!neonUrl.includes("postgresql://") && !neonUrl.includes("postgres://"))
  ) {
    result.recommendations.push(
      "‚ùå Set DATABASE_URL to Neon PostgreSQL connection string"
    );
    return result;
  }

  const prisma = new PrismaClient();
  try {
    await prisma.$queryRaw`SELECT 1`;
    console.log("‚úÖ Neon PostgreSQL connection successful");
  } catch (error) {
    result.recommendations.push(`‚ùå Database connection failed: ${error}`);
    return result;
  }

  // 2. Load and Analyze Source Data
  console.log("\nüìä Analyzing source CSV data...");

  const appointmentRows: any[] = [];
  const doorcardRows: any[] = [];

  // Read appointments
  await new Promise<void>((resolve, reject) => {
    fs.createReadStream("db-items/TBL_APPOINTMENT (1).csv")
      .pipe(parse({ headers: true }))
      .on("data", (row) => appointmentRows.push(row))
      .on("end", resolve)
      .on("error", reject);
  });

  // Read doorcards
  await new Promise<void>((resolve, reject) => {
    fs.createReadStream("db-items/TBL_DOORCARD (1).csv")
      .pipe(parse({ headers: true }))
      .on("data", (row) => doorcardRows.push(row))
      .on("end", resolve)
      .on("error", reject);
  });

  result.sourceData.appointments = appointmentRows.length;
  result.sourceData.doorcards = doorcardRows.length;

  // Extract unique users
  const uniqueUsernames = new Set([
    ...doorcardRows.map((row) => row.username).filter(Boolean),
    ...appointmentRows.map((row) => row.username).filter(Boolean),
  ]);
  result.sourceData.users = uniqueUsernames.size;

  console.log(
    `   üìà Source Data: ${result.sourceData.users} users, ${result.sourceData.doorcards} doorcards, ${result.sourceData.appointments} appointments`
  );

  // 3. Check for Constraint Violations
  console.log("\nüîç Checking for constraint violations...");

  // Check for duplicate users (shouldn't happen but let's verify)
  const usernameCounts = new Map<string, number>();
  [...doorcardRows, ...appointmentRows].forEach((row) => {
    if (row.username) {
      usernameCounts.set(
        row.username,
        (usernameCounts.get(row.username) || 0) + 1
      );
    }
  });

  // Check for doorcard constraint violations (userId + college + term + year + isActive)
  const doorcardConstraints = new Map<string, number>();
  const problematicDoorcards: Array<{
    username: string;
    college: string;
    count: number;
  }> = [];

  doorcardRows.forEach((row) => {
    if (row.username && row.college) {
      // Using FALL 2025 and isActive=true for all doorcards
      const constraintKey = `${row.username}-${row.college}-FALL-2025-true`;
      const count = (doorcardConstraints.get(constraintKey) || 0) + 1;
      doorcardConstraints.set(constraintKey, count);

      if (count > 1) {
        const existing = problematicDoorcards.find(
          (d) => d.username === row.username && d.college === row.college
        );
        if (existing) {
          existing.count = count;
        } else {
          problematicDoorcards.push({
            username: row.username,
            college: row.college,
            count,
          });
        }
      }
    }
  });

  result.constraints.duplicateDoorcards = problematicDoorcards;

  // Check for orphaned appointments
  const doorcardIds = new Set(doorcardRows.map((row) => row.doorcardID));
  const orphanedAppointments = appointmentRows.filter(
    (row) => row.doorcardID && !doorcardIds.has(row.doorcardID)
  );
  result.constraints.orphanedAppointments = orphanedAppointments.length;

  console.log(
    `   üö® Found ${result.constraints.duplicateDoorcards.length} users with multiple doorcards per college`
  );
  console.log(
    `   üö® Found ${result.constraints.orphanedAppointments} orphaned appointments`
  );

  if (result.constraints.duplicateDoorcards.length > 0) {
    console.log("\n   Top constraint violations:");
    result.constraints.duplicateDoorcards.slice(0, 10).forEach((item) => {
      console.log(
        `     - ${item.username} at ${item.college}: ${item.count} doorcards`
      );
    });
  }

  // 4. Generate Recommendations
  console.log("\nüí° RECOMMENDATIONS:");

  if (result.constraints.duplicateDoorcards.length > 0) {
    result.recommendations.push(
      `Handle ${result.constraints.duplicateDoorcards.length} constraint violations in doorcard creation`
    );
    console.log(`   ‚úÖ Constraint handling implemented in migration script`);
  }

  if (result.constraints.orphanedAppointments > 0) {
    result.recommendations.push(
      `${result.constraints.orphanedAppointments} appointments will be skipped (orphaned)`
    );
    console.log(
      `   ‚ö†Ô∏è  ${result.constraints.orphanedAppointments} appointments reference non-existent doorcards`
    );
  }

  result.recommendations.push("Use transaction-based migration for atomicity");
  result.recommendations.push(
    "Implement comprehensive logging and rollback capability"
  );
  result.recommendations.push("Validate final counts match expectations");

  // 5. Final Assessment
  result.canProceed = true; // We've handled the known issues

  console.log("\nüéØ FINAL ASSESSMENT:");
  console.log(
    `   Migration can proceed: ${result.canProceed ? "‚úÖ YES" : "‚ùå NO"}`
  );
  console.log(`   Expected final counts:`);
  console.log(`     - Users: ${result.sourceData.users}`);
  console.log(
    `     - Doorcards: ${result.sourceData.doorcards - result.constraints.duplicateDoorcards.reduce((sum, d) => sum + (d.count - 1), 0)} (after deduplication)`
  );
  console.log(
    `     - Appointments: ${result.sourceData.appointments - result.constraints.orphanedAppointments} (after filtering orphans)`
  );

  await prisma.$disconnect();
  return result;
}

if (require.main === module) {
  validateMigration()
    .then((result) => {
      console.log("\nüéâ VALIDATION COMPLETE!");
      process.exit(result.canProceed ? 0 : 1);
    })
    .catch((error) => {
      console.error("\n‚ùå VALIDATION FAILED:", error);
      process.exit(1);
    });
}
